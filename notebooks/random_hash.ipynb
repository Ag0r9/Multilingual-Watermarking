{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask and the pad token id were not set. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "Setting `pad_token_id` to `eos_token_id`:50256 for open-end generation.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[\"What's the meaning of life? Is it a metaphor for life or a metaphor for our existence? I'm trying to understand this in different ways, and there are a couple of different points you take away from my answers. First, you need to answer some of the interesting philosophical questions that people have raised on the topic. If you ask the people who are interested in this question, there are a few of them here. Second, if you think that the answers to these questions are a bit esoteric or not quite clear, that you\"]\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM, LogitsProcessor\n",
    "\n",
    "VOCAB_SIZE = 50257\n",
    "\n",
    "class RandomHashLogitsProcessor(LogitsProcessor):\n",
    "    def __init__(self, hash_function, vocab_size=VOCAB_SIZE):\n",
    "        self.hash_function = hash_function\n",
    "        self.vocab_size = vocab_size\n",
    "\n",
    "    def __call__(self, input_ids, logits, **kwargs):\n",
    "        random_hash = self.hash_function(input_ids, self.vocab_size)\n",
    "        modified_logits = logits + random_hash\n",
    "        return modified_logits\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"{self.__class__.__name__}(hash_function={self.hash_function})\"\n",
    "    \n",
    "    def __len__(self):\n",
    "        return 0\n",
    "\n",
    "# Define your hash function\n",
    "def random_hash_function(input_ids, vocab_size):\n",
    "    random_hash = torch.rand(input_ids.shape[0], vocab_size)\n",
    "    return random_hash\n",
    "\n",
    "# Load tokenizer and model\n",
    "tokenizer = AutoTokenizer.from_pretrained(\"gpt2\", vocab_size=VOCAB_SIZE)\n",
    "model = AutoModelForCausalLM.from_pretrained(\"gpt2\")\n",
    "\n",
    "# Create an instance of the RandomHashLogitsProcessor\n",
    "logits_processor = RandomHashLogitsProcessor(hash_function=random_hash_function)\n",
    "\n",
    "prompt = \"What's the meaning of life?\"\n",
    "inputs = tokenizer(prompt, return_tensors=\"pt\").input_ids\n",
    "\n",
    "# Generate predictions with modified logits\n",
    "outputs = model.generate(\n",
    "    inputs,\n",
    "    max_new_tokens=100,\n",
    "    do_sample=True,\n",
    "    top_k=50,\n",
    "    top_p=0.95,\n",
    "    logits_processor=logits_processor\n",
    ")\n",
    "\n",
    "# Decode the outputs\n",
    "decoded_outputs = tokenizer.batch_decode(outputs, skip_special_tokens=True)\n",
    "print(decoded_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "mlw-3.10",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
